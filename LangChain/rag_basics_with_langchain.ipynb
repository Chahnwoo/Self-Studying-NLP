{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain\n",
    "LangChain is a framework that essentially makes development with large language models easier for you. It allows you to tie together various elements that you might need for an LLM-based application (vector databases, models, prompts, etc.). In a modular manner, making it much easier on you to connect everything together with very few lines of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain Community\n",
    "LangChain has split up its many components into several sub-libraries, so you may have to do a little bit of digging through the [API documentation](https://api.python.langchain.com/en/latest/langchain_api_reference.html) to find what you are looking for. A lot of what you'll be looking for can be found in [LangChain Community](https://api.python.langchain.com/en/latest/community_api_reference.html), which is the sub-library that handles things like third-party integrations. Some integrations include those of OpenAI, HuggingFace, VLLM, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import langchain_community\n",
    "\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain_community.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval-Augmented Generation (RAG)\n",
    "In this demonstration, I will be introducing you to langchain by guiding you through the creation of a simplified RAG-based application. For those who aren't familiar with the topic, RAG stands for Retrieval-Augmented Generation. Like the phrase suggests, RAG is a method in which you RETRIEVE external information to AUGMENT your model to GENERATE in a certain way.\n",
    "\n",
    "Here's an example to make things a little more concrete:\n",
    "\n",
    "Imagine that you are trying to build an application with a large language model (GPT, LLaMA, Mistral, whichever you prefer) that has been pre-trained on data up to 2023. If you ask the model about the total solar eclipse that occurred on 8 Apr 2024, you couldn't possibly get an accurate answer, since the model is not psychic and cannot peer into the future. \n",
    "\n",
    "One option to fix the situation would be to train the model on current data. While this is an option, it isn't very viable, and is hardly worth the effort. The reality is that pre-training a model requires resources that most people don't have, and trying to repeatedly train a model to keep it up to date is probably not the best way to make use of your resources.\n",
    "\n",
    "Another approach you might take is connecting the model to an outside source of information, such as a website. You toss a query to the website, the website somehow finds resources that seem relevant to your query, and the LLM references those resources to create a response. This way, you don't have to worry about whether the model itself has been trained on that information; you're going to provide it with what it needs explicitly. This is an example of RAG.\n",
    "\n",
    "For now, we'll try implementing the example above using LangChain.\n",
    "\n",
    "First, we need a source of information that we can retrieve data from. While LangChain provides support for many different forms of data, we will begin with data from ArXiv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  arxiv pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "attention_doc = ArxivLoader(query = '1706.03762', load_max_docs = 1).load()\n",
    "print(attention_doc[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we delve into how the data above will be used, it may be helpful to discuss the structure of a LangChain `Document` since this is the form that LangChain loaders load data with. In the above code, the ArXiv loader loads a list of LangChain documents, where each `Document` contains the contents of a query result. Because we have set the `load_max_docs` parameter to 1, `attention_doc` will only contain a single LangChain Document, corresponding to a single query result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArXiv Loader return type :  <class 'list'>\n",
      "Length of return type :  1\n",
      "Type of each element :  <class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(\"ArXiv Loader return type : \", type(attention_doc))\n",
    "print(\"Length of return type : \", len(attention_doc))\n",
    "print(\"Type of each element : \", type(attention_doc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A LangChain `Document` is comprised of two components: `page_content` and `metadata`. Think of `page_content` as the actual text that the data originally holds. On the other hand, the `metadata` may contain all sorts of information, depending on what is available. Since the document above has been loaded from ArXiv, its `metadata` includes the paper's publication date, its title, authors, and a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Content :  Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and ...\n",
      "\n",
      "Metadata : \n",
      "'Published' : '2023-08-02'\n",
      "'Title' : 'Attention Is All You Need'\n",
      "'Authors' : 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin'\n",
      "'Summary' : 'The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks in an encoder-decoder configuration. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer, based\n",
      "solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine translation tasks show these models to be\n",
      "superior in quality while being more parallelizable and requiring significantly\n",
      "less time to train. Our model achieves 28.4 BLEU on the WMT 2014\n",
      "English-to-German translation task, improving over the existing best results,\n",
      "including ensembles by over 2 BLEU. On the WMT 2014 English-to-French\n",
      "translation task, our model establishes a new single-model state-of-the-art\n",
      "BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\n",
      "of the training costs of the best models from the literature. We show that the\n",
      "Transformer generalizes well to other tasks by applying it successfully to\n",
      "English constituency parsing both with large and limited training data.'\n"
     ]
    }
   ],
   "source": [
    "attention_doc = attention_doc[0]\n",
    "print(\"Page Content : \", attention_doc.page_content[:100], '...\\n')\n",
    "print(\"Metadata : \")\n",
    "for key in attention_doc.metadata.keys():\n",
    "    print(f\"'{key}' : '{attention_doc.metadata[key]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a basic understanding on the type of data we will be handling, we can proceed with setting up a retrieval system for our language model. Sure, we have a source of information, but this isn't enough. Given a question from a user, we want to provide our language model with enough context to come up with an answer. Tossing the whole document in for context is hardly a solution; the length of the inputs to a language model can have drastic impacts on its generation speed and quality. \n",
    "\n",
    "In other words, we want to accurately extract the parts of the text that are relevant to a given query, and provide those to the language model instead.\n",
    "\n",
    "To do this, we first split the contents of the document into multiple sub-texts, which we will call chunks. To do this, we use the text splitters provided by LangChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50,\n",
    "    length_function = len,\n",
    "    separators = ['\\n\\n', '\\n', ' ']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following explanations (as well as many from this point on) were written to help newcomers gain an intution on how RAG works as a whole; many details, while they are important, may be omitted for sake of coherence. \n",
    "\n",
    "The `chunk_size` determines an upper bound for the length of each chunk. Again, we don't want to shove too much text into our language models for a variety of reasons.\n",
    "\n",
    "The `chunk_overlap` parameter determines how much overlapping text there should be between each chunk. Because we are splitting our original text into sub-texts based purely on length (and not, for example, by sections or chapters), there may be instances in which texts that belong together are split apart; the chunk_overlap parameter helps mitigate this by acting as a sort of buffer.\n",
    "\n",
    "An interesting thing about the `RecursiveCharacterTextSplitter` is that it takes into consideration the `chunk_size` and `separators` to look for what seem like appropriate splitting points in the original text. For those interested the details of its workings, [DEV Community](https://dev.to/eteimz/understanding-langchains-recursivecharactertextsplitter-2846) has a pretty straightforward explanation about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu' metadata={'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}\n",
      "page_content='University of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,' metadata={'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}\n",
      "page_content='based solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,' metadata={'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}\n",
      "page_content='our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started' metadata={'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}\n",
      "page_content='the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and' metadata={'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}\n"
     ]
    }
   ],
   "source": [
    "split_docs = text_splitter.split_documents([attention_doc])\n",
    "\n",
    "# Show the first five examples\n",
    "for split_doc in split_docs[:5]:\n",
    "    print(split_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above segment of code, we can see that the original text has been successfully split into multiple chunks. One thing to note is that the `split_documents` function doesn't quite just take text and split it; we have the `split_text` function for that. Instead, the `split_documents` function takes an `Iterable` of LangChain Documents and splits those Documents into multiple new documents. So the `page_content` of each of the new Documents contains a portion of the original text, but how are the `metadata` of the new Documents created?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}\n",
      "{'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}\n",
      "{'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}\n",
      "{'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}\n",
      "{'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}\n"
     ]
    }
   ],
   "source": [
    "metadatas = [split_doc.metadata for split_doc in split_docs]\n",
    "\n",
    "# Show the first five examples\n",
    "for metadata in metadatas[:5]:\n",
    "    print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `metadata` of the original LangChain Document has been copied over to each of its children. Under the hood, the `split_documents` function performs two main operations:\n",
    "\n",
    "1. Split the `page_content` into multiple chunks and creates a new Document for each\n",
    "2. Copy the original Document's `metadata` for all of the newly generated Documents\n",
    "\n",
    "We now have data in the form that we want (chunks), but we still don't know how to determine which chunk corresponds to a particular query. We're going to be setting up a vector database to do that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-chroma --quiet\n",
    "\n",
    "from langchain_chroma import Chroma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector Databases\n",
    "For those familiar with relational databases, think of how one queries its contents with SQL. You look for rows of data that fit the criteria detailed by your query (`age > 8`, `country == Korea`). In essence, you are looking for exact matches. With vector databases, you are looking for *similar* matches instead. For that to make more sense, we must first understand embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name = 'sentence-transformers/all-mpnet-base-v2',\n",
    "    model_kwargs = {\n",
    "        'device' : 'cpu',\n",
    "    },\n",
    "    encode_kwargs = {\n",
    "        'normalize_embeddings' : True,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.030639825388789177,\n",
       " -0.00623022485524416,\n",
       " -0.0021215418819338083,\n",
       " 0.013879154808819294,\n",
       " 0.026486855000257492]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.embed_query('hello')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As AWS puts it, [\"Embedding models are algorithms trained to encapsulate information into dense representations in multi-dimensional space.\"](https://aws.amazon.com/what-is/embeddings-in-machine-learning/?nc1=h_ls) If you aren't familiar with vectors and higher-dimensional spaces, think of embedding models as algorithms that convert text into coordinates in the x-y plane. Somehow, the embedding model knows that points representing words or phrases similar or relevant to each other ('dog' and 'cat') should be placed nearby and that those that aren't should be spaced further apart ('giraffe' and 'tank'). [This image](https://miro.medium.com/v2/resize:fit:850/1*jptD3Rur8gUOftw-XHrezQ.png) from [this article](https://medium.com/@eugene-s/the-rise-of-embedding-technology-and-vector-databases-in-ai-4a8db58eb332) about embeddings might help if you're struggling to make sense of what that would look like.\n",
    "\n",
    "So those decimals in that cell above are actually the coordinates for a vector (or point if you would prefer) in an incredibly high-dimensional space (I've only printed the first five as a demonstration). Keep that in mind, but don't worry about picturing it; an image of the 3-dimensional or 2-dimensional alternative works fine for gaining intuition.\n",
    "\n",
    "What's nice about embedding models (and the vector embeddings that they create) is that they provide machines with a meaningful way to make comparisons. More specifically, it's obvious to us that the words 'child' and 'parent' have some sort of relationship, but a machine doesn't know that. If you give it two vector embeddings, however, a machine can tell you things like how far apart the two are and THAT can be used as concrete indicator of things like 'relevance' or 'similarity' - the smaller the distance between them, the closer the two vectors are, and the more likely they are to be relevant with one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector database (Chroma) using the ArXiv documents and embedding model from above\n",
    "chromadb = Chroma.from_documents(\n",
    "    documents = split_docs,\n",
    "    embedding = embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector databases work by representing the data contained within with vector embeddings. Think of them as a huge collection of `keys` and `values`. When data is added to a vector database, the data (corresponding to the `values`) is first converted into a vector embedding (`keys`) as you've seen above. These vector embeddings act as the 'key' that represent the data that has been added. So instead of looking for exact matches like a relational database, vector databases work by figuring out which entries seem most similar or relevant to the query (their vector embeddings are closest to the query).\n",
    "\n",
    "It does this effectively with Approximate Nearest Neighbor (ANN) algorithms like HNSW. The details of such algorithms are beyond the scope of this particular tutorial, but I have linked a few useful guides/tutorials in the Resources folder if you're interested.\n",
    "\n",
    "The search process, summarized, can be thought of as follows:\n",
    "1. Query is provided by user\n",
    "2. Query is converted into a vector embedding\n",
    "3. The vector database somehow identifies the `keys` (vectors) that are closest to the query vector embedding\n",
    "4. The vector database returns the `values` associated with those `keys`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.3\n",
      "Applications of Attention in our Model\n",
      "The Transformer uses multi-head attention in three different ways:\n",
      "• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\n",
      "and the memory keys and values come from the output of the encoder. This allows every\n",
      "position in the decoder to attend over all positions in the input sequence. This mimics the\n",
      "typical encoder-decoder attention mechanisms in sequence-to-sequence models such as\n",
      "[38, 2, 9].\n",
      "{'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Published': '2023-08-02', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.', 'Title': 'Attention Is All You Need'}\n"
     ]
    }
   ],
   "source": [
    "retrieved_document = chromadb.similarity_search('how is attention implemented in a transformers model?', k = 1)\n",
    "print(retrieved_document[0].page_content)\n",
    "print(retrieved_document[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple search seems to yield decent results; at the very least, the document returned by the vector database doesn't seem completely unrelated to the query we've provided. As a side note, the `similarity_search` function returns a list of LangChain Documents, which is why we need to perform indexing as we've done above. The size of the list is determined by the `k` paramter we've set at 1. \n",
    "\n",
    "So far we've done the following:\n",
    "1. Select the data to use for querying\n",
    "    - Attention is All You Need paper\n",
    "2. Prepared the data in a way that our language model can use\n",
    "    - Split text into chunks\n",
    "3. Prepared a way to select which of the data to hand over to the language model\n",
    "    - The vector database does this for us using an embedding model\n",
    "\n",
    "So now all that's left is to hand this information over to a language model that can use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet huggingface_hub==0.23.0 transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ba55c5b19a440e830f81c939b19afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cwpar\\anaconda3\\envs\\wheel_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "hf = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"max_new_tokens\": 200},\n",
    "    device_map = 'cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cwpar\\anaconda3\\envs\\wheel_env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Continue the fibonacci sequence, with 100 as an upper bound: 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75059, 121355, 196418, 317811, 514229, 832040, 1346264, 2178301, 3524578, 5702887, 9227465, 14930352'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf(\"Continue the fibonacci sequence, with 100 as an upper bound: 1, 1, 2, 3, 5, \")"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell above may not make much sense to those unfamilar with the HuggingFace libraries, but the details for that are beyond the scope of this introductory tutorial. For now, all that's important is that the `pipeline` that has been constructed above allows you to toss text into a language model and receive text back.\n",
    "\n",
    "Two things you can notice from the output of the cell above is that the language model we've chosen takes a substantial amount of time for generation, and that it does not seem to be listening to our directions. If you're used to using ChatGPT, the difference in generation quality may seem stark; ChatGPT does do a better job adhering to the instructions we've provided.\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "But keep in mind that the GPT models are models on a completely different scale altogether. The GPT-3 model contained 175B parameters, and the newest GPT-4 model is rumored to have a parameter size exceeding 1T. The `TinyLlama` model we are using, on the other hand, only has ~1B parameters. As a rule of thumb, models with more parameters generally perform better than smaller ones. It shouldn't be too surprising to find that a 1B model can't compete with a 1T model.\n",
    "\n",
    "If you have an OpenAI API account, feel free to substitute the above code with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms.openai import OpenAI\n",
    "# llm = OpenAI(\n",
    "#     openai_api_key = \"YOUR OPEN AI API KEY GOES HERE\",\n",
    "#     model = 'gpt-4-turbo'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a language model capable of generation, we want to provide it with some guidelines on *how* it will generate. This role is fulfilled by prompts, which can be thought of as instructions that may include details on how the model should treat its inputs and how it should format its outputs. Here's a sample to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "template = \"\"\"Instruction: \n",
    "Answer the following question using details from the context.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Context: \n",
    "{context}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = ['question', 'context'],\n",
    "    template = template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of the prompt template initialized above as a fill-in-the-blanks sheet. There exists a template that should be maintained no matter the input, and variables that serve as fields that accept data. Now think back to the overall structure of the RAG system we want to implement: we want to have a language model that uses data retrieved from a vector database to answer a question. Broken down into steps, that would look something like:\n",
    "1. Query the vector database\n",
    "2. Retrieve relevant documents from the vector database\n",
    "3. Provide the language model with those documents as context to generate an answer to the initial query\n",
    "\n",
    "The prompt template above is designed to enable Step 3. All that's left is to connect all the pieces we've made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(question : str):\n",
    "    relevant_docs = chromadb.similarity_search(query = question, k = 1)\n",
    "    context = relevant_docs[0].page_content\n",
    "    print(f\"> Context\\n{context}\\n\")\n",
    "    llm_prompt = prompt.format(question = question, context = context)\n",
    "    print(f\"> Prompt\\n{llm_prompt}\\n\")\n",
    "    return hf(llm_prompt)[len(llm_prompt):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Context\n",
      "3.2.3\n",
      "Applications of Attention in our Model\n",
      "The Transformer uses multi-head attention in three different ways:\n",
      "• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\n",
      "and the memory keys and values come from the output of the encoder. This allows every\n",
      "position in the decoder to attend over all positions in the input sequence. This mimics the\n",
      "typical encoder-decoder attention mechanisms in sequence-to-sequence models such as\n",
      "[38, 2, 9].\n",
      "\n",
      "> Prompt\n",
      "Instruction: \n",
      "Answer the following question using details from the context.\n",
      "\n",
      "Question:\n",
      "How is the attention mechanism implemented in a transformer model?\n",
      "\n",
      "Context: \n",
      "3.2.3\n",
      "Applications of Attention in our Model\n",
      "The Transformer uses multi-head attention in three different ways:\n",
      "• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\n",
      "and the memory keys and values come from the output of the encoder. This allows every\n",
      "position in the decoder to attend over all positions in the input sequence. This mimics the\n",
      "typical encoder-decoder attention mechanisms in sequence-to-sequence models such as\n",
      "[38, 2, 9].\n",
      "\n",
      "> LLM Result\n",
      " \n",
      "• In \"intermediate representation\" layers, the queries come from the output of the encoder,\n",
      "and the memory keys and values come from the output of the decoder. This allows the\n",
      "model to attend over the entire input sequence, and the output of the model is a\n",
      "combination of the encoder output and the decoder output. This is similar to the\n",
      "encoder-decoder attention mechanism in [38, 2, 9].\n",
      "• In \"output layer\" layers, the queries come from the output of the decoder, and the\n",
      "memory keys and values come from the output of the encoder. This allows the model to\n",
      "attend over the entire input sequence, and the output of the model is a combination of\n",
      "the encoder output and the decoder output. This is similar to the encoder-decoder\n",
      "attention mechanism in [38, 2, 9].\n",
      "\n",
      "Answer:\n",
      "The attention mechanism\n"
     ]
    }
   ],
   "source": [
    "print(\"> LLM Result\\n\", query('How is the attention mechanism implemented in a transformer model?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above cell, we can see that our function is behaving as expected. The vector database we had initialized earlier is queried for a relevant document, and this document is used to guide the language model in its generation. The quality of the generation, however, seems questionable. The language model isn't answering from the text we have provided it with. With a GPT model, however, results are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.openai import BaseOpenAI\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"YOUR OPENAI API KEY GOES HERE\"\n",
    "\n",
    "openai_llm = BaseOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(question : str):\n",
    "    relevant_docs = chromadb.similarity_search(query = question, k = 1)\n",
    "    context = relevant_docs[0].page_content\n",
    "    llm_prompt = prompt.format(question = question, context = context)\n",
    "    return openai_llm(prompt = llm_prompt, model = 'gpt-3.5-turbo-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> OpenAI Result\n",
      " \n",
      "\n",
      "The attention mechanism is implemented in a transformer model through multi-head attention, specifically in encoder-decoder attention layers. In this type of attention, the queries come from the previous decoder layer while the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence, mimicking the typical encoder-decoder attention mechanisms used in sequence-to-sequence models. \n"
     ]
    }
   ],
   "source": [
    "print(\"> OpenAI Result\\n\", query('How is the attention mechanism implemented in a transformer model?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disregarding the quality of the generations themselves, that's all there is to a basic RAG pipeline. The code above can actually be simplified to very few lines with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cwpar\\anaconda3\\envs\\wheel_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain, RetrievalQA\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50,\n",
    "    length_function = len,\n",
    "    separators = ['\\n\\n', '\\n', ' ']\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents = text_splitter.split_documents(ArxivLoader(query = '1706.03762', load_max_docs = 1).load()),\n",
    "    embedding = HuggingFaceEmbeddings(\n",
    "        model_name = 'sentence-transformers/all-mpnet-base-v2',\n",
    "        model_kwargs = {\n",
    "            'device' : 'cpu',\n",
    "        },\n",
    "        encode_kwargs = {\n",
    "            'normalize_embeddings' : True,\n",
    "        }\n",
    "    )\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "model = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"max_new_tokens\": 200},\n",
    "    device_map = 'cuda'\n",
    ")\n",
    "\n",
    "chain = RetrievalQA.from_llm(llm = model, retriever = retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use the following pieces of context to answer the question at the end. If you don\\'t know the answer, just say that you don\\'t know, don\\'t try to make up an answer.\\n\\nContext:\\n3.2.3\\nApplications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n\\nContext:\\n3.2.3\\nApplications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n\\nContext:\\n3.2.3\\nApplications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n\\nContext:\\n3.2.3\\nApplications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n\\nQuestion: How is the attention mechanism implemented in transformer models?\\nHelpful Answer:\\nThe attention mechanism in transformer models is implemented using multi-head attention, which is a type of attention mechanism that involves multiple attention heads. Each attention head is responsible for attending over a different portion of the input sequence. In the Transformer, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence. The attention mechanism is implemented using a combination of feed-forward networks and self-attention layers. The feed-forward network is used to compute the attention scores for each position in the input sequence, while the self-attention layers are used to compute the attention weights for each position in the output sequence.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(query = 'How is the attention mechanism implemented in transformer models?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
